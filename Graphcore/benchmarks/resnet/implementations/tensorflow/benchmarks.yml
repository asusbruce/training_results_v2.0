---
common_options: &common_options
   location:
      public_examples/applications/tensorflow/cnns/training
   output:
      - [Images/sec, 'throughput']
      - [accuracy, 'accuracy']
      - [loss, 'loss']

resnet50_single_ipu_training_synth:
   <<: *common_options
   description:
      ResNet training on a single Mk2 IPU, synthetic.
   cmd: >-
      python
         train.py
         --config mk2_resnet50_mlperf_pod16
         --replicas 1
         --epochs 1
         --no-validation
         --gradient-accumulation-count 144
         --synthetic-data
         --logs-per-epoch 16
         --BN-span 1
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 1
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 1
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 1

resnet50_single_ipu_training_real:
   <<: *common_options
   description:
      ResNet training on a single Mk2 IPU, real data.
   cmd: >-
      python
         train.py
         --config mk2_resnet50_mlperf_pod16
         --replicas 1
         --epochs 2
         --no-validation
         --gradient-accumulation-count 144
         --data-dir $DATASETS_DIR/
         --logs-per-epoch 16
         --BN-span 1
   env:
      POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 1
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 10
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 10

resnet50_4_ipu_training_synth:
   <<: *common_options
   description: |
      ResNet50 training with synthetic data on 4 IPUs, using the MLPerf ResNet
      configuration.
   cmd: >-
      poprun
         --mpi-global-args="--allow-run-as-root --tag-output"
         --mpi-local-args="-x TF_POPLAR_FLAGS"
         --numa-aware 1
         --ipus-per-replica 1
         --num-instances 2
         --num-replicas 4
      python3
         train.py
         --config mk2_resnet50_mlperf_pod16_lars
         --identical-replica-seeding
         --data-dir $DATASETS_DIR/
         --no-validation
         --epochs 1
         --synthetic-data
         --epochs-per-ckpt 0
         --gradient-accumulation-count 40
   env:
      TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 4
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 2
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 2


resnet50_4_ipu_training_real:
   <<: *common_options
   description: |
      ResNet50 training with real data on 4 IPUs, using the MLPerf ResNet
      configuration.
   cmd: >-
      poprun
         --mpi-global-args="--allow-run-as-root --tag-output"
         --mpi-local-args="-x TF_POPLAR_FLAGS -x POPLAR_RUNTIME_OPTIONS"
         --numa-aware 1
         --ipus-per-replica 1
         --num-instances 2
         --num-replicas 4
      python3
         train.py
         --config mk2_resnet50_mlperf_pod16_lars
         --identical-replica-seeding
         --data-dir $DATASETS_DIR/
         --no-validation
         --epochs 1
         --epochs-per-ckpt 0
         --gradient-accumulation-count 40
   env:
      TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
      POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 4
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 2
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 2
   readme:
      - "applications/tensorflow/cnns/training/README_Benchmarks.md"
      - "Training"
      - "ResNet-50 v1.5 Training"
      - "1 x IPU-M2000"


resnet50_16_ipu_training_synth:
   <<: *common_options
   description: |
      ResNet50 training with synthetic data on 16 IPUs, using the MLPerf
      ResNet configuration.
   cmd: >-
      poprun
         --mpi-global-args="--allow-run-as-root --tag-output"
         --mpi-local-args="-x TF_POPLAR_FLAGS"
         --numa-aware 1
         --ipus-per-replica 1
         --num-instances 8
         --num-replicas 16
      python3
         train.py
         --config mk2_resnet50_mlperf_pod16_lars
         --identical-replica-seeding
         --data-dir $DATASETS_DIR/
         --no-validation
         --epochs 2
         --synthetic-data
         --epochs-per-ckpt 0
   env:
      TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 16
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 8
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 8

resnet50_16_ipu_training_real:
   <<: *common_options
   description: |
      ResNet50 training with real data on 16 IPUs, using the MLPerf ResNet
      configuration.
   cmd: >-
      poprun
         --mpi-global-args="--allow-run-as-root --tag-output"
         --mpi-local-args="-x TF_POPLAR_FLAGS
           -x POPLAR_RUNTIME_OPTIONS
           -x POPLAR_ENGINE_OPTIONS"
         --numa-aware 1
         --ipus-per-replica 1
         --num-instances 8
         --num-replicas 16
      python3
         train.py
         --config mk2_resnet50_mlperf_pod16_lars
         --identical-replica-seeding
         --data-dir $DATASETS_DIR/
         --no-validation
         --epochs 2
         --epochs-per-ckpt 0
   env:
      TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
      POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
      POPLAR_ENGINE_OPTIONS: '{"target.hostSyncTimeout":"3000"}'
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 16
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 8
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 8
   readme:
      - "applications/tensorflow/cnns/training/README_Benchmarks.md"
      - "Training"
      - "ResNet-50 v1.5 Training"
      - "1 x IPU-POD16"


resnet50_16_ipu_training_convergence:
   <<: *common_options
   description: |
      ResNet50 training with real data on 16 IPUs, using the MLPerf ResNet
      configuration.
   cmd: >-
      poprun
         --mpi-global-args="--allow-run-as-root --tag-output"
         --mpi-local-args="-x TF_POPLAR_FLAGS
           -x POPLAR_RUNTIME_OPTIONS
           -x POPLAR_ENGINE_OPTIONS"
         --numa-aware 1
         --ipus-per-replica 1
         --num-instances 8
         --num-replicas 16
      python3
         train.py
         --config mk2_resnet50_mlperf_pod16_lars
         --identical-replica-seeding
         --seed 1
         --data-dir $DATASETS_DIR/
         --wandb
   env:
      TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
      POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
      POPLAR_ENGINE_OPTIONS: '{"target.hostSyncTimeout":"3000"}'
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 16
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 8
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 8

resnet50_64_ipu_training_real_convergence:
   <<: *common_options
   description: |
      ResNet50 training with real data, using the MLPerf ResNet configuration,
      testing convergence. Need to have a comma separated HOSTS env var set to
      run this benchmark as it requires multiple hosts.
   cmd: >-
      poprun
         --host $HOSTS
         --mpi-global-args="
            --allow-run-as-root
            --tag-output
            --mca oob_tcp_if_include $TCP_IF_INCLUDE
            --mca btl_tcp_if_include $TCP_IF_INCLUDE"
         --mpi-local-args="
            -x OPAL_PREFIX
            -x LD_LIBRARY_PATH
            -x PATH
            -x PYTHONPATH
            -x IPUOF_VIPU_API_TIMEOUT=600
            -x POPLAR_LOG_LEVEL=WARN
            -x TF_POPLAR_FLAGS
            -x DATASETS_DIR
            -x POPLAR_ENGINE_OPTIONS
            -x POPLAR_RUNTIME_OPTIONS"
         --update-partition=no
         --reset-partition=no
         --vipu-server-timeout 300
         --vipu-server-host "$VIPU_CLI_API_HOST"
         --vipu-partition=$PARTITION
         --numa-aware 1
         --ipus-per-replica 1
         --num-instances 16
         --num-replicas 64
      python3
         train.py
         --config mk2_resnet50_mlperf_pod64_lars
         --identical-replica-seeding
         --seed 1
         --data-dir $DATASETS_DIR/
         --logs-path .
         --wandb
   env:
      TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
      POPLAR_ENGINE_OPTIONS: '{"opt.enableMultiAccessCopies":"false",
         "target.hostSyncTimeout":"3000"}'
      POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 64
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 64
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 64
   readme:
      - "applications/tensorflow/cnns/training/README_Benchmarks.md"
      - "Training"
      - "ResNet-50 v1.5 Training"
      - "1 x IPU-POD64"

resnet50_128_ipu_training_real_convergence_train:
   <<: *common_options
   description: |
      ResNet50 validation with real data, using the MLPerf ResNet
      configuration, testing convergence. Need to have a comma separated
      HOSTS env var set to run this benchmark as it requires 8 hosts.
   cmd: >-
      poprun
         --host $HOSTS
         --mpi-global-args="
            --allow-run-as-root
            --tag-output
            --mca oob_tcp_if_include $TCP_IF_INCLUDE
            --mca btl_tcp_if_include $TCP_IF_INCLUDE"
         --mpi-local-args="
            -x OPAL_PREFIX
            -x LD_LIBRARY_PATH
            -x PATH
            -x PYTHONPATH
            -x IPUOF_VIPU_API_TIMEOUT=600
            -x POPLAR_LOG_LEVEL=WARN
            -x TF_POPLAR_FLAGS
            -x DATASETS_DIR
            -x POPLAR_ENGINE_OPTIONS
            -x POPLAR_RUNTIME_OPTIONS"
         --update-partition=yes
         --reset-partition=no
         --vipu-server-timeout 600
         --vipu-server-host "$VIPU_CLI_API_HOST"
         --vipu-partition=$PARTITION
         --numa-aware 1
         --ipus-per-replica 1
         --num-instances 64
         --num-replicas 128
         --executable-cache-path /localdata/johannesr/exec_cache
      python3
         train.py
         --config mk2_resnet50_mlperf_pod128_lars
         --identical-replica-seeding
         --data-dir $DATASETS_DIR/
         --logs-path .
         --seed 0
         --identical-replica-seeding
         --seed 1
         --wandb
   env:
      TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
      POPLAR_ENGINE_OPTIONS: '{"opt.enableMultiAccessCopies":"false",
         "target.hostSyncTimeout":"3000"}'
      POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 64
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 64
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 64
   readme:
      - "applications/tensorflow/cnns/training/README_Benchmarks.md"
      - "Training"
      - "ResNet-50 v1.5 Training"
      - "1 x IPU-POD128"


resnet50_256_ipu_training_real_convergence_train:
   <<: *common_options
   description: |
      ResNet50 validation with real data, using the MLPerf ResNet
      configuration, testing convergence. Need to have a comma separated
      HOSTS env var set to run this benchmark as it requires 8 hosts.
   cmd: >-
      poprun
         --host $HOSTS
         --mpi-global-args="
            --allow-run-as-root
            --tag-output
            --mca oob_tcp_if_include $TCP_IF_INCLUDE
            --mca btl_tcp_if_include $TCP_IF_INCLUDE"
         --mpi-local-args="
            -x OPAL_PREFIX
            -x LD_LIBRARY_PATH
            -x PATH
            -x PYTHONPATH
            -x IPUOF_VIPU_API_TIMEOUT=600
            -x POPLAR_LOG_LEVEL=WARN
            -x TF_POPLAR_FLAGS
            -x DATASETS_DIR
            -x POPLAR_ENGINE_OPTIONS
            -x POPLAR_RUNTIME_OPTIONS"
         --update-partition=yes
         --reset-partition=no
         --vipu-server-timeout 600
         --vipu-server-host "$VIPU_SERVER_HOST"
         --vipu-partition=$PARTITION
         --numa-aware 1
         --ipus-per-replica 1
         --num-instances 64
         --num-replicas 256
         --executable-cache-path /localdata/johannesr/exec_cache
      python3
         train.py
         --config mk2_resnet50_mlperf_pod256_lars
         --identical-replica-seeding
         --data-dir $DATASETS_DIR/
         --logs-path .
         --seed 0
         --identical-replica-seeding
         --seed 1
         --wandb
   env:
      TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
      POPLAR_ENGINE_OPTIONS: '{"opt.enableMultiAccessCopies":"false",
         "target.hostSyncTimeout":"3000"}'
      POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 64
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 64
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 64
   readme:
      - "applications/tensorflow/cnns/training/README_Benchmarks.md"
      - "Training"
      - "ResNet-50 v1.5 Training"
      - "1 x IPU-POD256"

resnext101_pipelined_training_2_replicas_2_shards_real:
   <<: *common_options
   description:
      ResNeXt101 training pipelined over 2*2 IPUs.
   cmd: >-
      poprun
         --mpi-global-args="
            --allow-run-as-root
            --tag-output"
         --mpi-local-args="-x POPLAR_RUNTIME_OPTIONS"
         --numa-aware 1
         --num-replicas 2
         --ipus-per-replica 2
         --num-instances 2
      python3 train.py
         --config mk2_resnext101_16ipus
         --replicas 2
         --ckpts-per-epoch 0
         --epochs 1
         --logs-per-epoch 16
         --no-validation
         --data-dir $DATASETS_DIR
         --gradient-accumulation-count 64
         --num-io-tiles 32
         --prefetch-depth 4
   env:
      POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 17
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 17
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 17
   readme:
      - "applications/tensorflow/cnns/training/README_Benchmarks.md"
      - "Training"
      - "ResNext-101 Training"
      - "1 x IPU-M2000"

resnext101_pipelined_training_2_replicas_2_shards_synthetic:
   <<: *common_options
   description:
      ResNeXt101 training pipelined over 2*2 IPUs on synthetic data.
   cmd: >-
      python3 train.py
         --config mk2_resnext101_16ipus
         --replicas 2
         --ckpts-per-epoch 0
         --epochs 1
         --logs-per-epoch 16
         --no-validation
         --synthetic-data
         --gradient-accumulation-count 64
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'

resnext101_pipelined_training_8_replicas_2_shards_real:
   <<: *common_options
   description:
      ResNeXt101 training pipelined over 2*8 IPUs.
   cmd: >-
      poprun
         --mpi-global-args="
            --allow-run-as-root
            --tag-output"
         --mpi-local-args="-x TF_POPLAR_FLAGS
            -x POPLAR_RUNTIME_OPTIONS"
         --numa-aware 1
         --num-replicas 8
         --ipus-per-replica 2
         --num-instances 8
      python3 train.py
         --config mk2_resnext101_16ipus
         --ckpts-per-epoch 0
         --epochs 1
         --logs-per-epoch 16
         --no-validation
         --data-dir $DATASETS_DIR
         --num-io-tiles 32
         --prefetch-depth 4
   env:
      TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
      POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 8
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 8
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 8
   readme:
      - "applications/tensorflow/cnns/training/README_Benchmarks.md"
      - "Training"
      - "ResNext-101 Training"
      - "1 x IPU-POD16"

resnext101_pipelined_training_8_replicas_2_shards_synthetic:
   <<: *common_options
   description:
      ResNeXt101 training pipelined over 2*8 IPUs on synthetic data.
   cmd: >-
      poprun
         --mpi-global-args="
            --allow-run-as-root
            --tag-output"
         --mpi-local-args="-x TF_POPLAR_FLAGS"
         --numa-aware 1
         --num-replicas 8
         --ipus-per-replica 2
         --num-instances 8
      python3 train.py
         --config mk2_resnext101_16ipus
         --ckpts-per-epoch 0
         --epochs 1
         --logs-per-epoch 16
         --no-validation
         --synthetic-data
   env:
      TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
   data:
      throughput:
         regexp: 'img\/sec: *(.*?),'
         skip: 1
      accuracy:
         reduction_type: 'final'
         regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
         skip: 1
      loss:
         reduction_type: 'final'
         regexp: 'loss:\s*([\d\.]+|nan)\,'
         skip: 1

EfficientNet-B0_pipelined_training_1xIPUM2000_synth:
  description:
    EfficientNet-B0 training pipelined on 4x IPUs using synthetic data.
  cmd: >-
    python3 train.py
      --model efficientnet
      --identical-replica-seeding
      --ckpts-per-epoch 0
      --model-size 0
      --data-dir $DATASETS_DIR/
      --dataset imagenet
      --shards 4
      --batch-size 16
      --pipeline
      --gradient-accumulation-count 64
      --pipeline-splits block2b block4a block6a
      --epochs 1
      --no-validation
      --enable-recomputation
      --pipeline-schedule Grouped
      --optimiser RMSprop
      --precision 16.32
      --disable-variable-offloading
      --available-memory-proportion 0.1
      --synthetic-data
      --enable-half-partials
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 1
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']

EfficientNet-B0_pipelined_training_1xIPUM2000_real:
  description:
    EfficientNet-B0 training pipelined on 4x IPUs.
  cmd: >-
    python3 train.py
      --model efficientnet
      --identical-replica-seeding
      --ckpts-per-epoch 0
      --model-size 0
      --data-dir $DATASETS_DIR/
      --dataset imagenet
      --shards 4
      --batch-size 16
      --pipeline
      --gradient-accumulation-count 64
      --pipeline-splits block2b block4a block6a
      --epochs 2
      --no-validation
      --enable-recomputation
      --pipeline-schedule Grouped
      --optimiser RMSprop
      --precision 16.32
      --disable-variable-offloading
      --available-memory-proportion 0.1
      --enable-half-partials
      --eight-bit-io
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 17
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']

G16-EfficientNet-B0_pipelined_training_1xIPUM2000_synth:
  description:
    GS-16 EfficientNet-B0 training pipelined on 4x IPUs using synthetic data.
  cmd: >-
    python3 train.py
      --model efficientnet
      --identical-replica-seeding
      --ckpts-per-epoch 0
      --model-size 0
      --data-dir $DATASETS_DIR/
      --dataset imagenet
      --shards 4
      --batch-size 32
      --pipeline
      --gradient-accumulation-count 32
      --pipeline-splits block2a/c block4a block5c
      --epochs 1
      --no-validation
      --enable-recomputation
      --pipeline-schedule Grouped
      --group-dim 16
      --expand-ratio 4
      --groups 4
      --optimiser RMSprop
      --precision 16.32
      --internal-exchange-optimisation-target balanced
      --synthetic-data
      --enable-half-partials
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 1
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']

G16-EfficientNet-B0_pipelined_training_1xIPUM2000_real:
  description:
    GS-16 EfficientNet-B0 training pipelined on 4x IPUs.
  cmd: >-
    python3 train.py
      --model efficientnet
      --ckpts-per-epoch 0
      --model-size 0
      --data-dir $DATASETS_DIR/
      --dataset imagenet
      --shards 4
      --batch-size 32
      --pipeline
      --gradient-accumulation-count 32
      --pipeline-splits block2a/c block4a block5c
      --epochs 2
      --no-validation
      --enable-recomputation
      --pipeline-schedule Grouped
      --group-dim 16 --expand-ratio 4
      --groups 4 --optimiser RMSprop
      --precision 16.32
      --internal-exchange-optimisation-target balanced
      --enable-half-partials
      --eight-bit-io
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 17
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']

# CLI option --synthetic-data measures the IPU-only Tput and disregards any
# host/CPU activity. To test with the effect of host IO included, use
# --generated-data/ To test Tput with real data, including the effect of
# all pre-processing, remove the env setting, and remove "--synthetic-data"
# and "--generated-data" command line option
EfficientNet-B4_pipelined_training_4xIPUM2000_real:
  description:
    EfficientNet-B4 training pipelined on 16x IPUs.
  cmd: >-
    poprun
      --mpi-global-args="--allow-run-as-root --tag-output"
      --mpi-local-args="-x POPLAR_RUNTIME_OPTIONS"
      --numa-aware 1
      --num-replicas 4
      --num-instances 4
      --ipus-per-replica 4
    python3 train.py
      --config mk2_efficientnet_b4_g1_16ipus
      --identical-replica-seeding
      --epochs 1
      --data-dir $DATASETS_DIR/
      --logs-per-epoch 16
      --no-validation
      --eight-bit-io
  env:
    POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 4
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']


EfficientNet-B4_pipelined_training_4xIPUM2000_synth:
  description:
    EfficientNet-B4 training pipelined on 16x IPUs using synthetic data.
  cmd: >-
    python3 train.py
      --config mk2_efficientnet_b4_g1_16ipus
      --identical-replica-seeding
      --epochs 1
      --logs-per-epoch 16
      --no-validation
      --synthetic-data
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 1
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']


EfficientNet-B4_pipelined_training_1xIPUM2000_synth:
  description:
    EfficientNet-B4 training pipelined on 4x IPUs using synthetic data.
  cmd: >-
    python3 train.py
      --config mk2_efficientnet_b4_g1_16ipus
      --identical-replica-seeding
      --epochs 1
      --data-dir $DATASETS_DIR/
      --logs-per-epoch 16
      --no-validation
      --replicas 1
      --synthetic-data
      --gradient-accumulation-count 256
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 1
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']

EfficientNet-B4_pipelined_training_1xIPUM2000_real:
  description:
    EfficientNet-B4 training pipelined on 4x IPUs.
  cmd: >-
    python3 train.py
      --config mk2_efficientnet_b4_g1_16ipus
      --identical-replica-seeding
      --epochs 1
      --data-dir $DATASETS_DIR/
      --logs-per-epoch 16
      --no-validation
      --replicas 1
      --gradient-accumulation-count 256
      --dataset-percentage-to-use 15
      --eight-bit-io
  env:
    POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 1
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']


G16-EfficientNet-B4_pipelined_training_1xIPUM2000_synth:
  description:
    GS-16 EfficientNet-B4 training pipelined on 2 IPUs using synthetic data.
  cmd: >-
    python3 train.py
      --config mk2_efficientnet_b4_g16_16ipus
      --identical-replica-seeding
      --epochs 1
      --logs-per-epoch 16
      --no-validation
      --replicas 2
      --synthetic-data
      --gradient-accumulation-count 1024
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 1
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']

G16-EfficientNet-B4_pipelined_training_1xIPUM2000_real:
  description:
    GS-16 EfficientNet-B4 training pipelined on 2 IPUs.
  cmd: >-
    poprun
      --mpi-global-args="--allow-run-as-root --tag-output"
      --mpi-local-args="-x POPLAR_RUNTIME_OPTIONS"
      --numa-aware 1
      --num-replicas 2
      --num-instances 2
      --ipus-per-replica 2
    python3 train.py
      --config mk2_efficientnet_b4_g16_16ipus
      --identical-replica-seeding
      --epochs 1
      --data-dir $DATASETS_DIR/
      --logs-per-epoch 16
      --no-validation
      --replicas 2
      --gradient-accumulation-count 1024
      --dataset-percentage-to-use 15
      --eight-bit-io
      --num-io-tiles 32
      --prefetch-depth 3
  env:
    POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 1
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']
  readme:
    - "applications/tensorflow/cnns/training/README_Benchmarks.md"
    - "Training"
    - "EfficientNet-B4 Training Modified Group Dim 16"
    - "1 x IPU-M2000"

G16-EfficientNet-B4_pipelined_training_4xIPUM2000_synth:
  description:
    GS-16 EfficientNet-B4 training pipelined on 16 IPUs using synthetic data.
  cmd: >-
    python3 train.py
      --config mk2_efficientnet_b4_g16_16ipus
      --identical-replica-seeding
      --epochs 1
      --logs-per-epoch 16
      --no-validation
      --synthetic-data
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 1
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']

G16-EfficientNet-B4_pipelined_training_4xIPUM2000_real:
  description:
    GS-16 EfficientNet-B4 training pipelined on 16 IPUs.
  cmd: >-
    poprun
      --mpi-global-args="--allow-run-as-root --tag-output"
      --mpi-local-args="-x POPLAR_RUNTIME_OPTIONS"
      --numa-aware 1
      --num-replicas 8
      --num-instances 8
      --ipus-per-replica 2
    python3 train.py
      --config mk2_efficientnet_b4_g16_16ipus
      --identical-replica-seeding
      --epochs 1
      --data-dir $DATASETS_DIR/
      --logs-per-epoch 16
      --no-validation
      --dataset-percentage-to-use 15
      --eight-bit-io
      --num-io-tiles 32
      --prefetch-depth 3
  env:
    POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 4
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']
  readme:
    - "applications/tensorflow/cnns/training/README_Benchmarks.md"
    - "Training"
    - "EfficientNet-B4 Training Modified Group Dim 16"
    - "1 x IPU-POD16"


G16_EfficientNet_B4_pipelined_training_convergence:
  description:
    GS-16 EfficientNet-B4 training, testing convergence on Pod64
  cmd: >-
    poprun
      --vv
      --host $HOSTS
      --mpi-global-args="--allow-run-as-root
      --tag-output
      --mca oob_tcp_if_include $TCP_IF_INCLUDE
      --mca btl_tcp_if_include $TCP_IF_INCLUDE"
      --mpi-local-args="-x OPAL_PREFIX
      -x LD_LIBRARY_PATH
      -x PATH
      -x PYTHONPATH
      -x IPUOF_VIPU_API_TIMEOUT=600
      -x POPLAR_LOG_LEVEL=WARN
      -x TF_POPLAR_FLAGS
      -x DATASETS_DIR
      -x POPLAR_ENGINE_OPTIONS
      -x POPLAR_TARGET_OPTIONS"
      --update-partition=no
      --reset-partition=no
      --vipu-server-timeout 300
      --vipu-server-host $VIPU_CLI_API_HOST
      --vipu-partition=$IPUOF_VIPU_API_PARTITION_ID
      --numa-aware 1
      --ipus-per-replica 2
      --num-instances 32
      --num-replicas 32
    python3 train.py
      --config mk2_efficientnet_b4_g16_64ipus
      --identical-replica-seeding
      --epochs 350
      --logs-per-epoch 16
      --epochs-per-ckpt 1
      --no-validation
      --data-dir $DATASETS_DIR
      --wandb
      --eight-bit-io
      --seed 1
      --num-io-tiles 32
      --prefetch-depth 3
      --log-dir ./logs/checkpoints
  env:
    TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
    POPLAR_ENGINE_OPTIONS: '{"opt.enableMultiAccessCopies":"false"}'
    POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 1
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']
  readme:
    - "applications/tensorflow/cnns/training/README_Benchmarks.md"
    - "Training"
    - "EfficientNet-B4 Training Modified Group Dim 16"
    - "1 x IPU-POD64"


G16_EfficientNet_B4_pipelined_training_convergence_pod256:
  description:
    GS-16 EfficientNet-B4 training, testing convergence on Pod256
  cmd: >-
    poprun
    --vv
    --host $HOSTS
    --mpi-global-args="--allow-run-as-root
    --tag-output
    --mca oob_tcp_if_include $TCP_IF_INCLUDE
    --mca btl_tcp_if_include $TCP_IF_INCLUDE"
    --mpi-local-args="-x OPAL_PREFIX
    -x LD_LIBRARY_PATH
    -x PATH
    -x PYTHONPATH
    -x IPUOF_VIPU_API_TIMEOUT=600
    -x POPLAR_LOG_LEVEL=WARN
    -x TF_POPLAR_FLAGS
    -x DATASETS_DIR
    -x POPLAR_ENGINE_OPTIONS
    -x POPLAR_TARGET_OPTIONS"
    --update-partition=no
    --reset-partition=no
    --vipu-server-timeout 300
    --vipu-server-host $VIPU_SERVER_HOST
    --vipu-partition=$IPUOF_VIPU_API_PARTITION_ID
    --numa-aware 1
    --ipus-per-replica 2
    --num-instances 32
    --num-replicas 32
    python3 train.py
      --config mk2_efficientnet_b4_g16_256ipus
      --identical-replica-seeding
      --epochs 350
      --logs-per-epoch 16
      --no-validation
      --data-dir $DATASETS_DIR
      --wandb
      --eight-bit-io
      --identical-replica-seeding
      --seed 1
      --num-io-tiles 32
      --prefetch-depth 3
      --log-dir ./logs
  env:
    TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
    POPLAR_ENGINE_OPTIONS: '{"opt.enableMultiAccessCopies":"false"}'
    POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 1
    accuracy:
      reduction_type: 'final'
      regexp: 'accuracy:\s*([\d\.]+|nan)\%\,'
      skip: 10
    loss:
      reduction_type: 'final'
      regexp: 'loss:\s*([\d\.]+|nan)\,'
      skip: 10
  output:
    - [Images/sec, 'throughput']
  readme:
    - "applications/tensorflow/cnns/training/README_Benchmarks.md"
    - "Training"
    - "EfficientNet-B4 Training Modified Group Dim 16"
    - "1 x IPU-POD256"


G16_EfficientNet_B4_pipelined_validation_convergence:
  description:
    GS-16 EfficientNet-B4 validation, testing convergence on Pod16
  cmd: >-
    python3
      validation.py
      --config mk2_efficientnet_b4_g16_16ipus
      --data-dir $DATASETS_DIR/imagenet-data
      --restore-path ./logs/checkpoints
      --log-dir ./logs/checkpoints
      --epochs-per-ckpt 1
      --logs-per-epoch 2
      --batch-size 25
      --shards 1
      --wandb
  env:
    TF_POPLAR_FLAGS: "--executable_cache_path=./tf_cache/"
    POPLAR_ENGINE_OPTIONS: '{"opt.enableMultiAccessCopies":"false"}'
    POPLAR_RUNTIME_OPTIONS: '{"streamCallbacks.maxLookahead":"unlimited"}'
  location:
    public_examples/applications/tensorflow/cnns/training
  data:
    throughput:
      regexp: 'img\/sec: *(.*?),'
      skip: 1
    accuracy:
      reduction_type: 'final'
      regexp: '\):\s*([\d\.]+|nan)\%'
  output:
    - [Accuracy, 'accuracy']
